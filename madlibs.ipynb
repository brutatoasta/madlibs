{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madlibs\n",
    "\n",
    "## Madlibs style word substitution\n",
    "Given a (multiline) f-string, match the substitutes to the targets. If the targets have no subs, put an empty string (default value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt one\n",
    "def g(inp:str, **subs) -> str:\n",
    "    return inp.format(**subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'w'\n"
     ]
    }
   ],
   "source": [
    "replacements = {\"x\":70}\n",
    "# replacements = {\"x\":70, \"w\":80, \"z\": 90}\n",
    "# replacements = {\"x\":70, \"w\":80, }\n",
    "\n",
    "sample = \"The number is {x} {w} {z}\"\n",
    "try:\n",
    "    test = g(sample, **replacements)\n",
    "    print(test)\n",
    "except KeyError as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: if the dict doesnt contain it, theres a keyerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2: use a custom formatter (PEP 3101)\n",
    "from string import Formatter\n",
    "from typing import Dict\n",
    "class MadLibber(Formatter):\n",
    "    def __init__(self, default=\"\") -> None:\n",
    "        super().__init__()\n",
    "        self.default=default\n",
    "\n",
    "    def get_value(self, key, args, kwds:Dict):\n",
    "        if isinstance(key, str):\n",
    "            return kwds.get(key, self.default)\n",
    "        else:\n",
    "            return super().get_value(key, args, kwds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number is 70  \n"
     ]
    }
   ],
   "source": [
    "mL = MadLibber()\n",
    "print(mL.format(sample, **replacements))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully we can improve on its inelegance. Also I dont fully understand the formatter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 3: format_map\n",
    "class Default(dict):\n",
    "    def __missing__(self, key):\n",
    "        return '{'+key+'}'\n",
    "class Default2(dict):\n",
    "    def __missing__(self, key):\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number is 70 {w} {z}\n",
      "The number is 70  \n"
     ]
    }
   ],
   "source": [
    "print(sample.format_map(Default(replacements)))\n",
    "print(sample.format_map(Default2(replacements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lorem Ipsum is interestingly dummy text of the printing \n",
      "and typesetting industry. Lorem Ipsum has been the \n",
      "industry's standard dummy text ever since the 1500s, \n",
      "when an unknown printer took a human of type and \n",
      "scrambled it to make a type specimen book. It has \n",
      "survived not only five centuries, but also the \n",
      "leap at electronic typesetting, remaining \n",
      "essentially unchanged. It was {verb} in the \n",
      "1960s with the release of Letraset sheets containing \n",
      "Lorem Ipsum passages, and more recently with \n",
      "desktop publishing software like Aldus PageMaker \n",
      "including versions of Lorem Ipsum.\n",
      "\n",
      "\n",
      "Lorem Ipsum is interestingly dummy text of the printing \n",
      "and typesetting industry. Lorem Ipsum has been the \n",
      "industry's standard dummy text ever since the 1500s, \n",
      "when an unknown printer took a human of type and \n",
      "scrambled it to make a type specimen book. It has \n",
      "survived not only five centuries, but also the \n",
      "leap at electronic typesetting, remaining \n",
      "essentially unchanged. It was  in the \n",
      "1960s with the release of Letraset sheets containing \n",
      "Lorem Ipsum passages, and more recently with \n",
      "desktop publishing software like Aldus PageMaker \n",
      "including versions of Lorem Ipsum.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multiline =\"\"\"\n",
    "Lorem Ipsum is {adj} dummy text of the printing \n",
    "and typesetting industry. Lorem Ipsum has been the \n",
    "industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a {noun} of type and \n",
    "scrambled it to make a type specimen book. It has \n",
    "survived not only five centuries, but also the \n",
    "leap {preposition} electronic typesetting, remaining \n",
    "essentially unchanged. It was {verb} in the \n",
    "1960s with the release of Letraset sheets containing \n",
    "Lorem Ipsum passages, and more recently with \n",
    "desktop publishing software like Aldus PageMaker \n",
    "including versions of Lorem Ipsum.\n",
    "\"\"\"\n",
    "subs = {\"adj\":\"interestingly\",\n",
    "        \"noun\": \"human\",\n",
    "        \"preposition\": \"at\"}\n",
    "print(multiline.format_map(Default(subs)))\n",
    "print(multiline.format_map(Default2(subs)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a corpus of passages\n",
    "Let's actually make a game! We want lots of different passages of similar lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract articles from https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail?resource=download\n",
    "df = pd.read_csv(\"archive/cnn_dailymail/test.csv\")\n",
    "articles_df = df['article'].str.replace('. ','.\\n', regex=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk.\n",
      "They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger.\n",
      "More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans.\n",
      "'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
      "Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches .\n",
      "Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane.\n",
      "But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News.\n",
      "The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch.\n",
      "While most airlines stick to a pitch of 31 inches or above, some fall below this.\n",
      "While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches.\n",
      "British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\n"
     ]
    }
   ],
   "source": [
    "# check the first article in a single file\n",
    "with open(\"passage.txt\", \"w\") as f:\n",
    "    text = articles_df.iloc[0]\n",
    "    print(text)\n",
    "    f.write(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to CSV\n",
    "articles_df.to_csv(\"articles.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "We want to use part-of-speech taggers to tag words to different \"parts of speech\": nouns, verbs, adjectives, adverbs, connectives, pronouns and prepositions, etc.\n",
    "This allows us to choose certain numbers of each word type to blank out.\n",
    "\n",
    "Let's try out spaCy on just the first article using this [guide](https://freecontent.manning.com/detecting-word-types-with-part-of-speech-tagging-part-1/).\n",
    "\n",
    "Note: We also have to run `py -m  spacy download en_core_web_sm` to download that model before we can use it. We're just using the small model for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc= nlp(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look inside them using the inspect module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "[('_', <spacy.tokens.underscore.Underscore object at 0x00000258851355D0>), ('__bytes__', <built-in method __bytes__ of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__class__', <class 'spacy.tokens.token.Token'>), ('__delattr__', <method-wrapper '__delattr__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__dir__', <built-in method __dir__ of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__doc__', 'An individual token â i.e. a word, punctuation symbol, whitespace,\\n    etc.\\n\\n    DOCS: https://spacy.io/api/token\\n    '), ('__eq__', <method-wrapper '__eq__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__format__', <built-in method __format__ of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__ge__', <method-wrapper '__ge__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__getattribute__', <method-wrapper '__getattribute__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__getstate__', <built-in method __getstate__ of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__gt__', <method-wrapper '__gt__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__hash__', <method-wrapper '__hash__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__init__', <method-wrapper '__init__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__init_subclass__', <built-in method __init_subclass__ of type object at 0x00007FF91A476680>), ('__le__', <method-wrapper '__le__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__len__', <method-wrapper '__len__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__lt__', <method-wrapper '__lt__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__ne__', <method-wrapper '__ne__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__new__', <built-in method __new__ of type object at 0x00007FF91A476680>), ('__pyx_vtable__', <capsule object NULL at 0x00000258FA44D560>), ('__reduce__', <built-in method __reduce__ of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__reduce_ex__', <built-in method __reduce_ex__ of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__repr__', <method-wrapper '__repr__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__setattr__', <method-wrapper '__setattr__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__sizeof__', <built-in method __sizeof__ of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__str__', <method-wrapper '__str__' of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('__subclasshook__', <built-in method __subclasshook__ of type object at 0x00007FF91A476680>), ('__unicode__', <built-in method __unicode__ of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('ancestors', <generator object at 0x00000258E1F11120>), ('check_flag', <built-in method check_flag of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('children', <generator object at 0x00000258FFF5DD80>), ('cluster', 0), ('conjuncts', ()), ('dep', 400), ('dep_', 'advmod'), ('doc', Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk.\n",
      "They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger.\n",
      "More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans.\n",
      "'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
      "Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches .\n",
      "Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane.\n",
      "But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News.\n",
      "The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch.\n",
      "While most airlines stick to a pitch of 31 inches or above, some fall below this.\n",
      "While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches.\n",
      "British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.), ('ent_id', 0), ('ent_id_', ''), ('ent_iob', 2), ('ent_iob_', 'O'), ('ent_kb_id', 0), ('ent_kb_id_', ''), ('ent_type', 0), ('ent_type_', ''), ('get_extension', <built-in method get_extension of type object at 0x00007FF91A476680>), ('has_dep', <built-in method has_dep of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('has_extension', <built-in method has_extension of type object at 0x00007FF91A476680>), ('has_head', <built-in method has_head of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('has_morph', <built-in method has_morph of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('has_vector', True), ('head', noticed), ('i', 0), ('idx', 0), ('iob_strings', <built-in method iob_strings of type object at 0x00007FF91A476680>), ('is_alpha', True), ('is_ancestor', <built-in method is_ancestor of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('is_ascii', True), ('is_bracket', False), ('is_currency', False), ('is_digit', False), ('is_left_punct', False), ('is_lower', False), ('is_oov', True), ('is_punct', False), ('is_quote', False), ('is_right_punct', False), ('is_sent_end', False), ('is_sent_start', True), ('is_space', False), ('is_stop', True), ('is_title', True), ('is_upper', False), ('lang', 14626626061804382878), ('lang_', 'en'), ('left_edge', Ever), ('lefts', <generator object at 0x00000258FFF5EB90>), ('lemma', 6231102377460051108), ('lemma_', 'ever'), ('lex', <spacy.lexeme.Lexeme object at 0x00000258FAAEE080>), ('lex_id', 18446744073709551615), ('like_email', False), ('like_num', False), ('like_url', False), ('lower', 6231102377460051108), ('lower_', 'ever'), ('morph', ), ('n_lefts', 0), ('n_rights', 0), ('nbor', <built-in method nbor of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('norm', 6231102377460051108), ('norm_', 'ever'), ('orth', 2773059238501700275), ('orth_', 'Ever'), ('pos', 86), ('pos_', 'ADV'), ('prefix', 9391737413944127320), ('prefix_', 'E'), ('prob', -20.0), ('rank', 18446744073709551615), ('remove_extension', <built-in method remove_extension of type object at 0x00007FF91A476680>), ('right_edge', Ever), ('rights', <generator object at 0x00000258FFF5F0A0>), ('sent', Ever noticed how plane seats appear to be getting smaller and smaller?), ('sent_start', False), ('sentiment', 0.0), ('set_extension', <built-in method set_extension of type object at 0x00007FF91A476680>), ('set_morph', <built-in method set_morph of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('shape', 10887629174180191697), ('shape_', 'Xxxx'), ('similarity', <built-in method similarity of spacy.tokens.token.Token object at 0x0000025886E51FD0>), ('subtree', <generator object at 0x00000258FFF5F130>), ('suffix', 16203534885047373824), ('suffix_', 'ver'), ('tag', 164681854541413346), ('tag_', 'RB'), ('tensor', array([-0.07184553, -0.9302304 , -0.73006535,  1.2915884 , -1.0359731 ,\n",
      "       -0.1195116 , -1.2526588 ,  0.9204892 ,  0.20767933,  0.28017503,\n",
      "        0.49438298,  0.38774186, -1.6882113 , -1.0387092 , -0.3684955 ,\n",
      "       -0.50255495,  0.5076666 ,  1.1881034 , -0.5336754 , -0.09835984,\n",
      "        0.492917  ,  1.5609666 , -0.6395641 , -0.94076854,  0.49880183,\n",
      "        0.20413038,  0.1570763 ,  0.2771397 , -1.098916  ,  2.110776  ,\n",
      "       -0.44341207, -1.3203061 , -0.45595247, -1.4575047 , -0.47104016,\n",
      "       -0.3748588 , -1.1220902 , -1.5707977 , -0.8935955 ,  0.44313544,\n",
      "       -0.60828793, -1.1125247 , -0.47742575,  1.610576  , -0.13716418,\n",
      "       -0.15332639,  0.1615834 , -0.53909004,  0.19828543, -0.07909888,\n",
      "        0.87506664,  1.8243896 , -1.0691816 ,  0.18287055, -0.22767681,\n",
      "        0.29082832,  1.496574  , -0.13391986,  0.24876338, -0.15891057,\n",
      "       -1.0254487 , -1.248685  , -0.11377096,  0.91737866,  1.6263001 ,\n",
      "       -0.33044344, -0.2641011 , -0.7404916 ,  1.216027  , -0.86630666,\n",
      "        2.3424048 , -0.4882728 , -1.8132323 , -0.09355935, -0.23157763,\n",
      "       -0.22756718,  2.5785778 , -1.192615  ,  0.10077649,  1.1563684 ,\n",
      "       -0.26681897,  0.40914065,  1.0094826 , -0.55101   ,  1.2868141 ,\n",
      "        0.49997193,  0.9247032 , -0.7862992 ,  0.29511917, -0.8391254 ,\n",
      "        1.4409583 , -0.4927289 ,  0.7783065 ,  1.5731335 ,  0.5966046 ,\n",
      "       -0.41717452], dtype=float32)), ('text', 'Ever'), ('text_with_ws', 'Ever '), ('vector', array([-0.07184553, -0.9302304 , -0.73006535,  1.2915884 , -1.0359731 ,\n",
      "       -0.1195116 , -1.2526588 ,  0.9204892 ,  0.20767933,  0.28017503,\n",
      "        0.49438298,  0.38774186, -1.6882113 , -1.0387092 , -0.3684955 ,\n",
      "       -0.50255495,  0.5076666 ,  1.1881034 , -0.5336754 , -0.09835984,\n",
      "        0.492917  ,  1.5609666 , -0.6395641 , -0.94076854,  0.49880183,\n",
      "        0.20413038,  0.1570763 ,  0.2771397 , -1.098916  ,  2.110776  ,\n",
      "       -0.44341207, -1.3203061 , -0.45595247, -1.4575047 , -0.47104016,\n",
      "       -0.3748588 , -1.1220902 , -1.5707977 , -0.8935955 ,  0.44313544,\n",
      "       -0.60828793, -1.1125247 , -0.47742575,  1.610576  , -0.13716418,\n",
      "       -0.15332639,  0.1615834 , -0.53909004,  0.19828543, -0.07909888,\n",
      "        0.87506664,  1.8243896 , -1.0691816 ,  0.18287055, -0.22767681,\n",
      "        0.29082832,  1.496574  , -0.13391986,  0.24876338, -0.15891057,\n",
      "       -1.0254487 , -1.248685  , -0.11377096,  0.91737866,  1.6263001 ,\n",
      "       -0.33044344, -0.2641011 , -0.7404916 ,  1.216027  , -0.86630666,\n",
      "        2.3424048 , -0.4882728 , -1.8132323 , -0.09355935, -0.23157763,\n",
      "       -0.22756718,  2.5785778 , -1.192615  ,  0.10077649,  1.1563684 ,\n",
      "       -0.26681897,  0.40914065,  1.0094826 , -0.55101   ,  1.2868141 ,\n",
      "        0.49997193,  0.9247032 , -0.7862992 ,  0.29511917, -0.8391254 ,\n",
      "        1.4409583 , -0.4927289 ,  0.7783065 ,  1.5731335 ,  0.5966046 ,\n",
      "       -0.41717452], dtype=float32)), ('vector_norm', 9.198789), ('vocab', <spacy.vocab.Vocab object at 0x00000258FFF5ECB0>), ('whitespace_', ' ')]\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(type(doc))\n",
    "print(inspect.getmembers(doc[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not very useful. Let's try a different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ever', 'ever', 'ADV', 'RB', 'advmod', 'Xxxx', True, True]\n"
     ]
    }
   ],
   "source": [
    "token = doc[0]\n",
    "print([token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ever', 'ADV', 'adverb']\n",
      "['noticed', 'VERB', 'verb']\n",
      "['how', 'SCONJ', 'subordinating conjunction']\n",
      "['plane', 'NOUN', 'noun']\n",
      "['seats', 'NOUN', 'noun']\n",
      "['appear', 'VERB', 'verb']\n",
      "['to', 'PART', 'particle']\n",
      "['be', 'AUX', 'auxiliary']\n",
      "['getting', 'VERB', 'verb']\n",
      "['smaller', 'ADJ', 'adjective']\n",
      "['and', 'CCONJ', 'coordinating conjunction']\n",
      "['smaller', 'ADJ', 'adjective']\n",
      "['?', 'PUNCT', 'punctuation']\n",
      "['With', 'ADP', 'adposition']\n",
      "['increasing', 'VERB', 'verb']\n",
      "['numbers', 'NOUN', 'noun']\n",
      "['of', 'ADP', 'adposition']\n",
      "['people', 'NOUN', 'noun']\n",
      "['taking', 'VERB', 'verb']\n",
      "['to', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n",
      "['skies', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['some', 'DET', 'determiner']\n",
      "['experts', 'NOUN', 'noun']\n",
      "['are', 'AUX', 'auxiliary']\n",
      "['questioning', 'VERB', 'verb']\n",
      "['if', 'SCONJ', 'subordinating conjunction']\n",
      "['having', 'VERB', 'verb']\n",
      "['such', 'ADJ', 'adjective']\n",
      "['packed', 'VERB', 'verb']\n",
      "['out', 'ADP', 'adposition']\n",
      "['planes', 'NOUN', 'noun']\n",
      "['is', 'AUX', 'auxiliary']\n",
      "['putting', 'VERB', 'verb']\n",
      "['passengers', 'NOUN', 'noun']\n",
      "['at', 'ADP', 'adposition']\n",
      "['risk', 'NOUN', 'noun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\n', 'SPACE', 'space']\n",
      "['They', 'PRON', 'pronoun']\n",
      "['say', 'VERB', 'verb']\n",
      "['that', 'SCONJ', 'subordinating conjunction']\n",
      "['the', 'DET', 'determiner']\n",
      "['shrinking', 'VERB', 'verb']\n",
      "['space', 'NOUN', 'noun']\n",
      "['on', 'ADP', 'adposition']\n",
      "['aeroplanes', 'NOUN', 'noun']\n",
      "['is', 'AUX', 'auxiliary']\n",
      "['not', 'PART', 'particle']\n",
      "['only', 'ADV', 'adverb']\n",
      "['uncomfortable', 'ADJ', 'adjective']\n",
      "['-', 'PUNCT', 'punctuation']\n",
      "['it', 'PRON', 'pronoun']\n",
      "[\"'s\", 'AUX', 'auxiliary']\n",
      "['putting', 'VERB', 'verb']\n",
      "['our', 'PRON', 'pronoun']\n",
      "['health', 'NOUN', 'noun']\n",
      "['and', 'CCONJ', 'coordinating conjunction']\n",
      "['safety', 'NOUN', 'noun']\n",
      "['in', 'ADP', 'adposition']\n",
      "['danger', 'NOUN', 'noun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\n', 'SPACE', 'space']\n",
      "['More', 'ADJ', 'adjective']\n",
      "['than', 'ADP', 'adposition']\n",
      "['squabbling', 'VERB', 'verb']\n",
      "['over', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n",
      "['arm', 'NOUN', 'noun']\n",
      "['rest', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['shrinking', 'VERB', 'verb']\n",
      "['space', 'NOUN', 'noun']\n",
      "['on', 'ADP', 'adposition']\n",
      "['planes', 'NOUN', 'noun']\n",
      "['putting', 'VERB', 'verb']\n",
      "['our', 'PRON', 'pronoun']\n",
      "['health', 'NOUN', 'noun']\n",
      "['and', 'CCONJ', 'coordinating conjunction']\n",
      "['safety', 'NOUN', 'noun']\n",
      "['in', 'ADP', 'adposition']\n",
      "['danger', 'NOUN', 'noun']\n",
      "['?', 'PUNCT', 'punctuation']\n",
      "['This', 'DET', 'determiner']\n",
      "['week', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['a', 'DET', 'determiner']\n",
      "['U.S', 'PROPN', 'proper noun']\n",
      "['consumer', 'NOUN', 'noun']\n",
      "['advisory', 'NOUN', 'noun']\n",
      "['group', 'NOUN', 'noun']\n",
      "['set', 'VERB', 'verb']\n",
      "['up', 'ADP', 'adposition']\n",
      "['by', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n",
      "['Department', 'PROPN', 'proper noun']\n",
      "['of', 'ADP', 'adposition']\n",
      "['Transportation', 'PROPN', 'proper noun']\n",
      "['said', 'VERB', 'verb']\n",
      "['at', 'ADP', 'adposition']\n",
      "['a', 'DET', 'determiner']\n",
      "['public', 'ADJ', 'adjective']\n",
      "['hearing', 'NOUN', 'noun']\n",
      "['that', 'SCONJ', 'subordinating conjunction']\n",
      "['while', 'SCONJ', 'subordinating conjunction']\n",
      "['the', 'DET', 'determiner']\n",
      "['government', 'NOUN', 'noun']\n",
      "['is', 'AUX', 'auxiliary']\n",
      "['happy', 'ADJ', 'adjective']\n",
      "['to', 'PART', 'particle']\n",
      "['set', 'VERB', 'verb']\n",
      "['standards', 'NOUN', 'noun']\n",
      "['for', 'ADP', 'adposition']\n",
      "['animals', 'NOUN', 'noun']\n",
      "['flying', 'VERB', 'verb']\n",
      "['on', 'ADP', 'adposition']\n",
      "['planes', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['it', 'PRON', 'pronoun']\n",
      "['does', 'AUX', 'auxiliary']\n",
      "[\"n't\", 'PART', 'particle']\n",
      "['stipulate', 'VERB', 'verb']\n",
      "['a', 'DET', 'determiner']\n",
      "['minimum', 'ADJ', 'adjective']\n",
      "['amount', 'NOUN', 'noun']\n",
      "['of', 'ADP', 'adposition']\n",
      "['space', 'NOUN', 'noun']\n",
      "['for', 'ADP', 'adposition']\n",
      "['humans', 'NOUN', 'noun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\n', 'SPACE', 'space']\n",
      "[\"'\", 'PUNCT', 'punctuation']\n",
      "['In', 'ADP', 'adposition']\n",
      "['a', 'DET', 'determiner']\n",
      "['world', 'NOUN', 'noun']\n",
      "['where', 'SCONJ', 'subordinating conjunction']\n",
      "['animals', 'NOUN', 'noun']\n",
      "['have', 'VERB', 'verb']\n",
      "['more', 'ADJ', 'adjective']\n",
      "['rights', 'NOUN', 'noun']\n",
      "['to', 'ADP', 'adposition']\n",
      "['space', 'NOUN', 'noun']\n",
      "['and', 'CCONJ', 'coordinating conjunction']\n",
      "['food', 'NOUN', 'noun']\n",
      "['than', 'ADP', 'adposition']\n",
      "['humans', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "[\"'\", 'PUNCT', 'punctuation']\n",
      "['said', 'VERB', 'verb']\n",
      "['Charlie', 'PROPN', 'proper noun']\n",
      "['Leocha', 'PROPN', 'proper noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['consumer', 'NOUN', 'noun']\n",
      "['representative', 'NOUN', 'noun']\n",
      "['on', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n",
      "['committee', 'NOUN', 'noun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\xa0', 'SPACE', 'space']\n",
      "[\"'\", 'PUNCT', 'punctuation']\n",
      "['It', 'PRON', 'pronoun']\n",
      "['is', 'AUX', 'auxiliary']\n",
      "['time', 'NOUN', 'noun']\n",
      "['that', 'SCONJ', 'subordinating conjunction']\n",
      "['the', 'DET', 'determiner']\n",
      "['DOT', 'PROPN', 'proper noun']\n",
      "['and', 'CCONJ', 'coordinating conjunction']\n",
      "['FAA', 'PROPN', 'proper noun']\n",
      "['take', 'VERB', 'verb']\n",
      "['a', 'DET', 'determiner']\n",
      "['stand', 'NOUN', 'noun']\n",
      "['for', 'ADP', 'adposition']\n",
      "['humane', 'ADJ', 'adjective']\n",
      "['treatment', 'NOUN', 'noun']\n",
      "['of', 'ADP', 'adposition']\n",
      "['passengers', 'NOUN', 'noun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "[\"'\", 'PUNCT', 'punctuation']\n",
      "['But', 'CCONJ', 'coordinating conjunction']\n",
      "['could', 'AUX', 'auxiliary']\n",
      "['crowding', 'VERB', 'verb']\n",
      "['on', 'ADP', 'adposition']\n",
      "['planes', 'NOUN', 'noun']\n",
      "['lead', 'NOUN', 'noun']\n",
      "['to', 'ADP', 'adposition']\n",
      "['more', 'ADV', 'adverb']\n",
      "['serious', 'ADJ', 'adjective']\n",
      "['issues', 'NOUN', 'noun']\n",
      "['than', 'ADP', 'adposition']\n",
      "['fighting', 'VERB', 'verb']\n",
      "['for', 'ADP', 'adposition']\n",
      "['space', 'NOUN', 'noun']\n",
      "['in', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n",
      "['overhead', 'ADJ', 'adjective']\n",
      "['lockers', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['crashing', 'VERB', 'verb']\n",
      "['elbows', 'NOUN', 'noun']\n",
      "['and', 'CCONJ', 'coordinating conjunction']\n",
      "['seat', 'VERB', 'verb']\n",
      "['back', 'ADP', 'adposition']\n",
      "['kicking', 'NOUN', 'noun']\n",
      "['?', 'PUNCT', 'punctuation']\n",
      "['Tests', 'NOUN', 'noun']\n",
      "['conducted', 'VERB', 'verb']\n",
      "['by', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n",
      "['FAA', 'PROPN', 'proper noun']\n",
      "['use', 'NOUN', 'noun']\n",
      "['planes', 'NOUN', 'noun']\n",
      "['with', 'ADP', 'adposition']\n",
      "['a', 'DET', 'determiner']\n",
      "['31', 'NUM', 'numeral']\n",
      "['inch', 'NOUN', 'noun']\n",
      "['pitch', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['a', 'DET', 'determiner']\n",
      "['standard', 'NOUN', 'noun']\n",
      "['which', 'PRON', 'pronoun']\n",
      "['on', 'ADP', 'adposition']\n",
      "['some', 'DET', 'determiner']\n",
      "['airlines', 'NOUN', 'noun']\n",
      "['has', 'AUX', 'auxiliary']\n",
      "['decreased', 'VERB', 'verb']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\n', 'SPACE', 'space']\n",
      "['Many', 'ADJ', 'adjective']\n",
      "['economy', 'NOUN', 'noun']\n",
      "['seats', 'NOUN', 'noun']\n",
      "['on', 'ADP', 'adposition']\n",
      "['United', 'PROPN', 'proper noun']\n",
      "['Airlines', 'PROPN', 'proper noun']\n",
      "['have', 'VERB', 'verb']\n",
      "['30', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "['of', 'ADP', 'adposition']\n",
      "['room', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['while', 'SCONJ', 'subordinating conjunction']\n",
      "['some', 'DET', 'determiner']\n",
      "['airlines', 'NOUN', 'noun']\n",
      "['offer', 'VERB', 'verb']\n",
      "['as', 'ADV', 'adverb']\n",
      "['little', 'ADJ', 'adjective']\n",
      "['as', 'ADP', 'adposition']\n",
      "['28', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\n', 'SPACE', 'space']\n",
      "['Cynthia', 'PROPN', 'proper noun']\n",
      "['Corbertt', 'PROPN', 'proper noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['a', 'DET', 'determiner']\n",
      "['human', 'ADJ', 'adjective']\n",
      "['factors', 'NOUN', 'noun']\n",
      "['researcher', 'NOUN', 'noun']\n",
      "['with', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n",
      "['Federal', 'PROPN', 'proper noun']\n",
      "['Aviation', 'PROPN', 'proper noun']\n",
      "['Administration', 'PROPN', 'proper noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['that', 'SCONJ', 'subordinating conjunction']\n",
      "['it', 'PRON', 'pronoun']\n",
      "['conducts', 'VERB', 'verb']\n",
      "['tests', 'NOUN', 'noun']\n",
      "['on', 'ADP', 'adposition']\n",
      "['how', 'SCONJ', 'subordinating conjunction']\n",
      "['quickly', 'ADV', 'adverb']\n",
      "['passengers', 'NOUN', 'noun']\n",
      "['can', 'AUX', 'auxiliary']\n",
      "['leave', 'VERB', 'verb']\n",
      "['a', 'DET', 'determiner']\n",
      "['plane', 'NOUN', 'noun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\n', 'SPACE', 'space']\n",
      "['But', 'CCONJ', 'coordinating conjunction']\n",
      "['these', 'DET', 'determiner']\n",
      "['tests', 'NOUN', 'noun']\n",
      "['are', 'AUX', 'auxiliary']\n",
      "['conducted', 'VERB', 'verb']\n",
      "['using', 'VERB', 'verb']\n",
      "['planes', 'NOUN', 'noun']\n",
      "['with', 'ADP', 'adposition']\n",
      "['31', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "['between', 'ADP', 'adposition']\n",
      "['each', 'DET', 'determiner']\n",
      "['row', 'NOUN', 'noun']\n",
      "['of', 'ADP', 'adposition']\n",
      "['seats', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['a', 'DET', 'determiner']\n",
      "['standard', 'NOUN', 'noun']\n",
      "['which', 'PRON', 'pronoun']\n",
      "['on', 'ADP', 'adposition']\n",
      "['some', 'DET', 'determiner']\n",
      "['airlines', 'NOUN', 'noun']\n",
      "['has', 'AUX', 'auxiliary']\n",
      "['decreased', 'VERB', 'verb']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['reported', 'VERB', 'verb']\n",
      "['the', 'DET', 'determiner']\n",
      "['Detroit', 'PROPN', 'proper noun']\n",
      "['News', 'PROPN', 'proper noun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\n', 'SPACE', 'space']\n",
      "['The', 'DET', 'determiner']\n",
      "['distance', 'NOUN', 'noun']\n",
      "['between', 'ADP', 'adposition']\n",
      "['two', 'NUM', 'numeral']\n",
      "['seats', 'NOUN', 'noun']\n",
      "['from', 'ADP', 'adposition']\n",
      "['one', 'NUM', 'numeral']\n",
      "['point', 'NOUN', 'noun']\n",
      "['on', 'ADP', 'adposition']\n",
      "['a', 'DET', 'determiner']\n",
      "['seat', 'NOUN', 'noun']\n",
      "['to', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n",
      "['same', 'ADJ', 'adjective']\n",
      "['point', 'NOUN', 'noun']\n",
      "['on', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n",
      "['seat', 'NOUN', 'noun']\n",
      "['behind', 'ADP', 'adposition']\n",
      "['it', 'PRON', 'pronoun']\n",
      "['is', 'AUX', 'auxiliary']\n",
      "['known', 'VERB', 'verb']\n",
      "['as', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n",
      "['pitch', 'NOUN', 'noun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\n', 'SPACE', 'space']\n",
      "['While', 'SCONJ', 'subordinating conjunction']\n",
      "['most', 'ADJ', 'adjective']\n",
      "['airlines', 'NOUN', 'noun']\n",
      "['stick', 'VERB', 'verb']\n",
      "['to', 'ADP', 'adposition']\n",
      "['a', 'DET', 'determiner']\n",
      "['pitch', 'NOUN', 'noun']\n",
      "['of', 'ADP', 'adposition']\n",
      "['31', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "['or', 'CCONJ', 'coordinating conjunction']\n",
      "['above', 'ADV', 'adverb']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['some', 'PRON', 'pronoun']\n",
      "['fall', 'VERB', 'verb']\n",
      "['below', 'ADP', 'adposition']\n",
      "['this', 'PRON', 'pronoun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\n', 'SPACE', 'space']\n",
      "['While', 'SCONJ', 'subordinating conjunction']\n",
      "['United', 'PROPN', 'proper noun']\n",
      "['Airlines', 'PROPN', 'proper noun']\n",
      "['has', 'VERB', 'verb']\n",
      "['30', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "['of', 'ADP', 'adposition']\n",
      "['space', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['Gulf', 'PROPN', 'proper noun']\n",
      "['Air', 'PROPN', 'proper noun']\n",
      "['economy', 'NOUN', 'noun']\n",
      "['seats', 'NOUN', 'noun']\n",
      "['have', 'VERB', 'verb']\n",
      "['between', 'ADP', 'adposition']\n",
      "['29', 'NUM', 'numeral']\n",
      "['and', 'CCONJ', 'coordinating conjunction']\n",
      "['32', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['Air', 'PROPN', 'proper noun']\n",
      "['Asia', 'PROPN', 'proper noun']\n",
      "['offers', 'VERB', 'verb']\n",
      "['29', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "['and', 'CCONJ', 'coordinating conjunction']\n",
      "['Spirit', 'PROPN', 'proper noun']\n",
      "['Airlines', 'PROPN', 'proper noun']\n",
      "['offers', 'VERB', 'verb']\n",
      "['just', 'ADV', 'adverb']\n",
      "['28', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "['.', 'PUNCT', 'punctuation']\n",
      "['\\n', 'SPACE', 'space']\n",
      "['British', 'PROPN', 'proper noun']\n",
      "['Airways', 'PROPN', 'proper noun']\n",
      "['has', 'VERB', 'verb']\n",
      "['a', 'DET', 'determiner']\n",
      "['seat', 'NOUN', 'noun']\n",
      "['pitch', 'NOUN', 'noun']\n",
      "['of', 'ADP', 'adposition']\n",
      "['31', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['while', 'SCONJ', 'subordinating conjunction']\n",
      "['easyJet', 'PUNCT', 'punctuation']\n",
      "['has', 'VERB', 'verb']\n",
      "['29', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['Thomson', 'PROPN', 'proper noun']\n",
      "[\"'s\", 'PART', 'particle']\n",
      "['short', 'ADJ', 'adjective']\n",
      "['haul', 'NOUN', 'noun']\n",
      "['seat', 'NOUN', 'noun']\n",
      "['pitch', 'NOUN', 'noun']\n",
      "['is', 'AUX', 'auxiliary']\n",
      "['28', 'NUM', 'numeral']\n",
      "['inches', 'NOUN', 'noun']\n",
      "[',', 'PUNCT', 'punctuation']\n",
      "['and', 'CCONJ', 'coordinating conjunction']\n",
      "['Virgin', 'PROPN', 'proper noun']\n",
      "['Atlantic', 'PROPN', 'proper noun']\n",
      "[\"'s\", 'PART', 'particle']\n",
      "['is', 'AUX', 'auxiliary']\n",
      "['30', 'NUM', 'numeral']\n",
      "['-', 'SYM', 'symbol']\n",
      "['31', 'NUM', 'numeral']\n",
      "['.', 'PUNCT', 'punctuation']\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print([token.text, token.pos_, spacy.explain(token.pos_)]) # .pos is an int, .pos_ is a string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we've got POS tagging done! Now to put take out certain parts of the text.\n",
    "\n",
    "We use spacy's matcher to look for words with certain POS tags, such as verbs, and replace them with a placeholder or suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6360137228241296794 verb 1 2 noticed\n",
      "6360137228241296794 verb 5 6 appear\n",
      "6360137228241296794 verb 8 9 getting\n",
      "6360137228241296794 verb 14 15 increasing\n",
      "6360137228241296794 verb 18 19 taking\n",
      "6360137228241296794 verb 26 27 questioning\n",
      "6360137228241296794 verb 28 29 having\n",
      "6360137228241296794 verb 30 31 packed\n",
      "6360137228241296794 verb 34 35 putting\n",
      "6360137228241296794 verb 41 42 say\n",
      "6360137228241296794 verb 44 45 shrinking\n",
      "6360137228241296794 verb 55 56 putting\n",
      "6360137228241296794 verb 66 67 squabbling\n",
      "6360137228241296794 verb 72 73 shrinking\n",
      "6360137228241296794 verb 76 77 putting\n",
      "6360137228241296794 verb 92 93 set\n",
      "6360137228241296794 verb 99 100 said\n",
      "6360137228241296794 verb 111 112 set\n",
      "6360137228241296794 verb 115 116 flying\n",
      "6360137228241296794 verb 122 123 stipulate\n",
      "6360137228241296794 verb 138 139 have\n",
      "6360137228241296794 verb 149 150 said\n",
      "6360137228241296794 verb 169 170 take\n",
      "6360137228241296794 verb 181 182 crowding\n",
      "6360137228241296794 verb 190 191 fighting\n",
      "6360137228241296794 verb 198 199 crashing\n",
      "6360137228241296794 verb 201 202 seat\n",
      "6360137228241296794 verb 206 207 conducted\n",
      "6360137228241296794 verb 225 226 decreased\n",
      "6360137228241296794 verb 234 235 have\n",
      "6360137228241296794 verb 243 244 offer\n",
      "6360137228241296794 verb 266 267 conducts\n",
      "6360137228241296794 verb 273 274 leave\n",
      "6360137228241296794 verb 282 283 conducted\n",
      "6360137228241296794 verb 282 284 conducted using\n",
      "6360137228241296794 verb 283 284 using\n",
      "6360137228241296794 verb 301 302 decreased\n",
      "6360137228241296794 verb 303 304 reported\n",
      "6360137228241296794 verb 330 331 known\n",
      "6360137228241296794 verb 339 340 stick\n",
      "6360137228241296794 verb 350 351 fall\n",
      "6360137228241296794 verb 358 359 has\n",
      "6360137228241296794 verb 368 369 have\n",
      "6360137228241296794 verb 377 378 offers\n",
      "6360137228241296794 verb 383 384 offers\n",
      "6360137228241296794 verb 391 392 has\n",
      "6360137228241296794 verb 401 402 has\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\n",
    "        \"POS\" :\"VERB\", # match verbs\n",
    "    \"OP\":\"*\"           # match 0 or more verbs\n",
    "    }\n",
    "    ]\n",
    "matcher.add(\"verb\", [pattern])\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: A [Span](https://spacy.io/api/span) is a slice from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ever <verb, past tense> how plane seats <verb, non-3rd person singular present> to be <verb, gerund or present participle> smaller and smaller? With <verb, gerund or present participle> numbers of people <verb, gerund or present participle> to the skies, some experts are <verb, gerund or present participle> if <verb, gerund or present participle> such <verb, past participle> out planes is <verb, gerund or present participle> passengers at risk.\\nThey <verb, non-3rd person singular present> that the <verb, gerund or present participle> space on aeroplanes is not only uncomfortable - it's <verb, gerund or present participle> our health and safety in danger.\\nMore than <verb, gerund or present participle> over the arm rest, <verb, gerund or present participle> space on planes <verb, gerund or present participle> our health and safety in danger? This week, a U.S consumer advisory group <verb, past participle> up by the Department of Transportation <verb, past tense> at a public hearing that while the government is happy to <verb, base form> standards for animals <verb, gerund or present participle> on planes, it doesn't <verb, base form> a minimum amount of space for humans.\\n'In a world where animals <verb, non-3rd person singular present> more rights to space and food than humans,' <verb, past tense> Charlie Leocha, consumer representative on the committee.\\xa0'It is time that the DOT and FAA <verb, base form> a stand for humane treatment of passengers.' But could <verb, gerund or present participle> on planes lead to more serious issues than <verb, gerund or present participle> for space in the overhead lockers, <verb, gerund or present participle> elbows and <verb, base form> back kicking? Tests <verb, past participle> by the FAA use planes with a 31 inch pitch, a standard which on some airlines has <verb, past participle> .\\nMany economy seats on United Airlines <verb, non-3rd person singular present> 30 inches of room, while some airlines <verb, non-3rd person singular present> as little as 28 inches .\\nCynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it <verb, 3rd person singular present> tests on how quickly passengers can <verb, base form> a plane.\\nBut these tests are <verb, past participle> <verb, past participle> <verb, gerund or present participle> planes with 31 inches between each row of seats, a standard which on some airlines has <verb, past participle>, <verb, past tense> the Detroit News.\\nThe distance between two seats from one point on a seat to the same point on the seat behind it is <verb, past participle> as the pitch.\\nWhile most airlines <verb, non-3rd person singular present> to a pitch of 31 inches or above, some <verb, non-3rd person singular present> below this.\\nWhile United Airlines <verb, 3rd person singular present> 30 inches of space, Gulf Air economy seats <verb, non-3rd person singular present> between 29 and 32 inches, Air Asia <verb, 3rd person singular present> 29 inches and Spirit Airlines <verb, 3rd person singular present> just 28 inches.\\nBritish Airways <verb, 3rd person singular present> a seat pitch of 31 inches, while easyJet <verb, 3rd person singular present> 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_word(orig_doc):\n",
    "    text = ''\n",
    "    buffer_start = 0\n",
    "    for _, match_start, _ in matcher(orig_doc):\n",
    "        if match_start > buffer_start:  # If we've skipped over some tokens, let's add those in (with trailing whitespace if available)\n",
    "            text += orig_doc[buffer_start: match_start].text + orig_doc[match_start - 1].whitespace_\n",
    "            \n",
    "        token = orig_doc[match_start]\n",
    "        tense = token.morph.get('Tense')[0] if token.morph.get('Tense') else \"\"\n",
    "        long_pos = spacy.explain(token.pos_)\n",
    "        tag = spacy.explain(token.tag_)\n",
    "        replacement = f\"<{tag}>\"\n",
    "        text += replacement + token.whitespace_  # Replace token, with trailing whitespace if available\n",
    "        buffer_start = match_start + 1\n",
    "    text += orig_doc[buffer_start:].text\n",
    "    return text\n",
    "\n",
    "replace_word(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've replace all verbs in a given text with a suggestion (that's a tad verbose). Let's try finding the number of each POS in a text, as both absolute number and percentage of the word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk.\n",
       "They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger.\n",
       "More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans.\n",
       "'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
       "Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches .\n",
       "Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane.\n",
       "But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News.\n",
       "The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch.\n",
       "While most airlines stick to a pitch of 31 inches or above, some fall below this.\n",
       "While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches.\n",
       "British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
