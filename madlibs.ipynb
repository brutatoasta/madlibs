{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madlibs\n",
    "\n",
    "## Madlibs style word substitution\n",
    "Given a (multiline) f-string, match the substitutes to the targets. If the targets have no subs, put an empty string (default value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt one\n",
    "def g(inp:str, **subs) -> str:\n",
    "    return inp.format(**subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'w'\n"
     ]
    }
   ],
   "source": [
    "replacements = {\"x\":70}\n",
    "# replacements = {\"x\":70, \"w\":80, \"z\": 90}\n",
    "# replacements = {\"x\":70, \"w\":80, }\n",
    "\n",
    "sample = \"The number is {x} {w} {z}\"\n",
    "try:\n",
    "    test = g(sample, **replacements)\n",
    "    print(test)\n",
    "except KeyError as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: if the dict doesnt contain it, theres a keyerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2: use a custom formatter (PEP 3101)\n",
    "from string import Formatter\n",
    "from typing import Dict\n",
    "class MadLibber(Formatter):\n",
    "    def __init__(self, default=\"\") -> None:\n",
    "        super().__init__()\n",
    "        self.default=default\n",
    "\n",
    "    def get_value(self, key, args, kwds:Dict):\n",
    "        if isinstance(key, str):\n",
    "            return kwds.get(key, self.default)\n",
    "        else:\n",
    "            return super().get_value(key, args, kwds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number is 70  \n"
     ]
    }
   ],
   "source": [
    "mL = MadLibber()\n",
    "print(mL.format(sample, **replacements))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully we can improve on its inelegance. Also I dont fully understand the formatter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 3: format_map\n",
    "class Default(dict):\n",
    "    def __missing__(self, key):\n",
    "        return '{'+key+'}'\n",
    "class Default2(dict):\n",
    "    def __missing__(self, key):\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number is 70 {w} {z}\n",
      "The number is 70  \n"
     ]
    }
   ],
   "source": [
    "print(sample.format_map(Default(replacements)))\n",
    "print(sample.format_map(Default2(replacements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lorem Ipsum is interestingly dummy text of the printing \n",
      "and typesetting industry. Lorem Ipsum has been the \n",
      "industry's standard dummy text ever since the 1500s, \n",
      "when an unknown printer took a human of type and \n",
      "scrambled it to make a type specimen book. It has \n",
      "survived not only five centuries, but also the \n",
      "leap at electronic typesetting, remaining \n",
      "essentially unchanged. It was {verb} in the \n",
      "1960s with the release of Letraset sheets containing \n",
      "Lorem Ipsum passages, and more recently with \n",
      "desktop publishing software like Aldus PageMaker \n",
      "including versions of Lorem Ipsum.\n",
      "\n",
      "\n",
      "Lorem Ipsum is interestingly dummy text of the printing \n",
      "and typesetting industry. Lorem Ipsum has been the \n",
      "industry's standard dummy text ever since the 1500s, \n",
      "when an unknown printer took a human of type and \n",
      "scrambled it to make a type specimen book. It has \n",
      "survived not only five centuries, but also the \n",
      "leap at electronic typesetting, remaining \n",
      "essentially unchanged. It was  in the \n",
      "1960s with the release of Letraset sheets containing \n",
      "Lorem Ipsum passages, and more recently with \n",
      "desktop publishing software like Aldus PageMaker \n",
      "including versions of Lorem Ipsum.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multiline =\"\"\"\n",
    "Lorem Ipsum is {adj} dummy text of the printing \n",
    "and typesetting industry. Lorem Ipsum has been the \n",
    "industry's standard dummy text ever since the 1500s, \n",
    "when an unknown printer took a {noun} of type and \n",
    "scrambled it to make a type specimen book. It has \n",
    "survived not only five centuries, but also the \n",
    "leap {preposition} electronic typesetting, remaining \n",
    "essentially unchanged. It was {verb} in the \n",
    "1960s with the release of Letraset sheets containing \n",
    "Lorem Ipsum passages, and more recently with \n",
    "desktop publishing software like Aldus PageMaker \n",
    "including versions of Lorem Ipsum.\n",
    "\"\"\"\n",
    "subs = {\"adj\":\"interestingly\",\n",
    "        \"noun\": \"human\",\n",
    "        \"preposition\": \"at\"}\n",
    "print(multiline.format_map(Default(subs)))\n",
    "print(multiline.format_map(Default2(subs)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a corpus of passages\n",
    "Let's actually make a game! We want lots of different passages of similar lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import inspect\n",
    "import random\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract articles from https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail?resource=download\n",
    "df = pd.read_csv(\"archive/cnn_dailymail/test.csv\")\n",
    "articles_df = df['article'].str.replace('. ','.\\n', regex=False) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk.\n",
      "They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger.\n",
      "More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans.\n",
      "'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
      "Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches .\n",
      "Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane.\n",
      "But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News.\n",
      "The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch.\n",
      "While most airlines stick to a pitch of 31 inches or above, some fall below this.\n",
      "While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches.\n",
      "British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\n"
     ]
    }
   ],
   "source": [
    "# check the first article in a single file\n",
    "with open(\"passage.txt\", \"w\") as f:\n",
    "    text = articles_df.iloc[0]\n",
    "    print(text)\n",
    "    f.write(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to CSV\n",
    "articles_df.to_csv(\"articles.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "We want to use part-of-speech taggers to tag words to different \"parts of speech\": nouns, verbs, adjectives, adverbs, connectives, pronouns and prepositions, etc.\n",
    "This allows us to choose certain numbers of each word type to blank out.\n",
    "\n",
    "Let's try out spaCy on just the first article using this [guide](https://freecontent.manning.com/detecting-word-types-with-part-of-speech-tagging-part-1/).\n",
    "\n",
    "Note: We also have to run `py -m  spacy download en_core_web_sm` to download that model before we can use it. We're just using the small model for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc= nlp(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look inside them using the inspect module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "[('_', <spacy.tokens.underscore.Underscore object at 0x0000016E0A4E9D50>), ('__bytes__', <built-in method __bytes__ of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__class__', <class 'spacy.tokens.token.Token'>), ('__delattr__', <method-wrapper '__delattr__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__dir__', <built-in method __dir__ of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__doc__', 'An individual token â i.e. a word, punctuation symbol, whitespace,\\n    etc.\\n\\n    DOCS: https://spacy.io/api/token\\n    '), ('__eq__', <method-wrapper '__eq__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__format__', <built-in method __format__ of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__ge__', <method-wrapper '__ge__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__getattribute__', <method-wrapper '__getattribute__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__getstate__', <built-in method __getstate__ of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__gt__', <method-wrapper '__gt__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__hash__', <method-wrapper '__hash__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__init__', <method-wrapper '__init__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__init_subclass__', <built-in method __init_subclass__ of type object at 0x00007FF91A286680>), ('__le__', <method-wrapper '__le__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__len__', <method-wrapper '__len__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__lt__', <method-wrapper '__lt__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__ne__', <method-wrapper '__ne__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__new__', <built-in method __new__ of type object at 0x00007FF91A286680>), ('__pyx_vtable__', <capsule object NULL at 0x0000016E047C3510>), ('__reduce__', <built-in method __reduce__ of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__reduce_ex__', <built-in method __reduce_ex__ of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__repr__', <method-wrapper '__repr__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__setattr__', <method-wrapper '__setattr__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__sizeof__', <built-in method __sizeof__ of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__str__', <method-wrapper '__str__' of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('__subclasshook__', <built-in method __subclasshook__ of type object at 0x00007FF91A286680>), ('__unicode__', <built-in method __unicode__ of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('ancestors', <generator object at 0x0000016E06017D90>), ('check_flag', <built-in method check_flag of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('children', <generator object at 0x0000016E142DB760>), ('cluster', 0), ('conjuncts', ()), ('dep', 400), ('dep_', 'advmod'), ('doc', Ever noticed how plane seats appear to be getting smaller and smaller? With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk.\n",
      "They say that the shrinking space on aeroplanes is not only uncomfortable - it's putting our health and safety in danger.\n",
      "More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger? This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing that while the government is happy to set standards for animals flying on planes, it doesn't stipulate a minimum amount of space for humans.\n",
      "'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to more serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking? Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
      "Many economy seats on United Airlines have 30 inches of room, while some airlines offer as little as 28 inches .\n",
      "Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it conducts tests on how quickly passengers can leave a plane.\n",
      "But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News.\n",
      "The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch.\n",
      "While most airlines stick to a pitch of 31 inches or above, some fall below this.\n",
      "While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers just 28 inches.\n",
      "British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.), ('ent_id', 0), ('ent_id_', ''), ('ent_iob', 2), ('ent_iob_', 'O'), ('ent_kb_id', 0), ('ent_kb_id_', ''), ('ent_type', 0), ('ent_type_', ''), ('get_extension', <built-in method get_extension of type object at 0x00007FF91A286680>), ('has_dep', <built-in method has_dep of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('has_extension', <built-in method has_extension of type object at 0x00007FF91A286680>), ('has_head', <built-in method has_head of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('has_morph', <built-in method has_morph of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('has_vector', True), ('head', noticed), ('i', 0), ('idx', 0), ('iob_strings', <built-in method iob_strings of type object at 0x00007FF91A286680>), ('is_alpha', True), ('is_ancestor', <built-in method is_ancestor of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('is_ascii', True), ('is_bracket', False), ('is_currency', False), ('is_digit', False), ('is_left_punct', False), ('is_lower', False), ('is_oov', True), ('is_punct', False), ('is_quote', False), ('is_right_punct', False), ('is_sent_end', False), ('is_sent_start', True), ('is_space', False), ('is_stop', True), ('is_title', True), ('is_upper', False), ('lang', 14626626061804382878), ('lang_', 'en'), ('left_edge', Ever), ('lefts', <generator object at 0x0000016E142DB880>), ('lemma', 6231102377460051108), ('lemma_', 'ever'), ('lex', <spacy.lexeme.Lexeme object at 0x0000016E0AB681C0>), ('lex_id', 18446744073709551615), ('like_email', False), ('like_num', False), ('like_url', False), ('lower', 6231102377460051108), ('lower_', 'ever'), ('morph', ), ('n_lefts', 0), ('n_rights', 0), ('nbor', <built-in method nbor of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('norm', 6231102377460051108), ('norm_', 'ever'), ('orth', 2773059238501700275), ('orth_', 'Ever'), ('pos', 86), ('pos_', 'ADV'), ('prefix', 9391737413944127320), ('prefix_', 'E'), ('prob', -20.0), ('rank', 18446744073709551615), ('remove_extension', <built-in method remove_extension of type object at 0x00007FF91A286680>), ('right_edge', Ever), ('rights', <generator object at 0x0000016E142DAE60>), ('sent', Ever noticed how plane seats appear to be getting smaller and smaller?), ('sent_start', False), ('sentiment', 0.0), ('set_extension', <built-in method set_extension of type object at 0x00007FF91A286680>), ('set_morph', <built-in method set_morph of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('shape', 10887629174180191697), ('shape_', 'Xxxx'), ('similarity', <built-in method similarity of spacy.tokens.token.Token object at 0x0000016E14167FB0>), ('subtree', <generator object at 0x0000016E142DB250>), ('suffix', 16203534885047373824), ('suffix_', 'ver'), ('tag', 164681854541413346), ('tag_', 'RB'), ('tensor', array([-0.07184553, -0.9302304 , -0.73006535,  1.2915884 , -1.0359731 ,\n",
      "       -0.1195116 , -1.2526588 ,  0.9204892 ,  0.20767933,  0.28017503,\n",
      "        0.49438298,  0.38774186, -1.6882113 , -1.0387092 , -0.3684955 ,\n",
      "       -0.50255495,  0.5076666 ,  1.1881034 , -0.5336754 , -0.09835984,\n",
      "        0.492917  ,  1.5609666 , -0.6395641 , -0.94076854,  0.49880183,\n",
      "        0.20413038,  0.1570763 ,  0.2771397 , -1.098916  ,  2.110776  ,\n",
      "       -0.44341207, -1.3203061 , -0.45595247, -1.4575047 , -0.47104016,\n",
      "       -0.3748588 , -1.1220902 , -1.5707977 , -0.8935955 ,  0.44313544,\n",
      "       -0.60828793, -1.1125247 , -0.47742575,  1.610576  , -0.13716418,\n",
      "       -0.15332639,  0.1615834 , -0.53909004,  0.19828543, -0.07909888,\n",
      "        0.87506664,  1.8243896 , -1.0691816 ,  0.18287055, -0.22767681,\n",
      "        0.29082832,  1.496574  , -0.13391986,  0.24876338, -0.15891057,\n",
      "       -1.0254487 , -1.248685  , -0.11377096,  0.91737866,  1.6263001 ,\n",
      "       -0.33044344, -0.2641011 , -0.7404916 ,  1.216027  , -0.86630666,\n",
      "        2.3424048 , -0.4882728 , -1.8132323 , -0.09355935, -0.23157763,\n",
      "       -0.22756718,  2.5785778 , -1.192615  ,  0.10077649,  1.1563684 ,\n",
      "       -0.26681897,  0.40914065,  1.0094826 , -0.55101   ,  1.2868141 ,\n",
      "        0.49997193,  0.9247032 , -0.7862992 ,  0.29511917, -0.8391254 ,\n",
      "        1.4409583 , -0.4927289 ,  0.7783065 ,  1.5731335 ,  0.5966046 ,\n",
      "       -0.41717452], dtype=float32)), ('text', 'Ever'), ('text_with_ws', 'Ever '), ('vector', array([-0.07184553, -0.9302304 , -0.73006535,  1.2915884 , -1.0359731 ,\n",
      "       -0.1195116 , -1.2526588 ,  0.9204892 ,  0.20767933,  0.28017503,\n",
      "        0.49438298,  0.38774186, -1.6882113 , -1.0387092 , -0.3684955 ,\n",
      "       -0.50255495,  0.5076666 ,  1.1881034 , -0.5336754 , -0.09835984,\n",
      "        0.492917  ,  1.5609666 , -0.6395641 , -0.94076854,  0.49880183,\n",
      "        0.20413038,  0.1570763 ,  0.2771397 , -1.098916  ,  2.110776  ,\n",
      "       -0.44341207, -1.3203061 , -0.45595247, -1.4575047 , -0.47104016,\n",
      "       -0.3748588 , -1.1220902 , -1.5707977 , -0.8935955 ,  0.44313544,\n",
      "       -0.60828793, -1.1125247 , -0.47742575,  1.610576  , -0.13716418,\n",
      "       -0.15332639,  0.1615834 , -0.53909004,  0.19828543, -0.07909888,\n",
      "        0.87506664,  1.8243896 , -1.0691816 ,  0.18287055, -0.22767681,\n",
      "        0.29082832,  1.496574  , -0.13391986,  0.24876338, -0.15891057,\n",
      "       -1.0254487 , -1.248685  , -0.11377096,  0.91737866,  1.6263001 ,\n",
      "       -0.33044344, -0.2641011 , -0.7404916 ,  1.216027  , -0.86630666,\n",
      "        2.3424048 , -0.4882728 , -1.8132323 , -0.09355935, -0.23157763,\n",
      "       -0.22756718,  2.5785778 , -1.192615  ,  0.10077649,  1.1563684 ,\n",
      "       -0.26681897,  0.40914065,  1.0094826 , -0.55101   ,  1.2868141 ,\n",
      "        0.49997193,  0.9247032 , -0.7862992 ,  0.29511917, -0.8391254 ,\n",
      "        1.4409583 , -0.4927289 ,  0.7783065 ,  1.5731335 ,  0.5966046 ,\n",
      "       -0.41717452], dtype=float32)), ('vector_norm', 9.198789), ('vocab', <spacy.vocab.Vocab object at 0x0000016E142DBE20>), ('whitespace_', ' ')]\n"
     ]
    }
   ],
   "source": [
    "print(type(doc))\n",
    "print(inspect.getmembers(doc[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not very useful. Let's try a different approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ever', 'ever', 'ADV', 'RB', 'advmod', 'Xxxx', True, True]\n"
     ]
    }
   ],
   "source": [
    "token = doc[0]\n",
    "print([token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ever', 'ADV', 'adverb']\n",
      "['noticed', 'VERB', 'verb']\n",
      "['how', 'SCONJ', 'subordinating conjunction']\n",
      "['plane', 'NOUN', 'noun']\n",
      "['seats', 'NOUN', 'noun']\n",
      "['appear', 'VERB', 'verb']\n",
      "['to', 'PART', 'particle']\n",
      "['be', 'AUX', 'auxiliary']\n",
      "['getting', 'VERB', 'verb']\n",
      "['smaller', 'ADJ', 'adjective']\n",
      "['and', 'CCONJ', 'coordinating conjunction']\n",
      "['smaller', 'ADJ', 'adjective']\n",
      "['?', 'PUNCT', 'punctuation']\n",
      "['With', 'ADP', 'adposition']\n",
      "['increasing', 'VERB', 'verb']\n",
      "['numbers', 'NOUN', 'noun']\n",
      "['of', 'ADP', 'adposition']\n",
      "['people', 'NOUN', 'noun']\n",
      "['taking', 'VERB', 'verb']\n",
      "['to', 'ADP', 'adposition']\n",
      "['the', 'DET', 'determiner']\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:len(doc)//20]: # limit output\n",
    "    print([token.text, token.pos_, spacy.explain(token.pos_)]) # .pos is an int, .pos_ is a string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we've got POS tagging done! Now to put take out certain parts of the text.\n",
    "\n",
    "We use spacy's matcher to look for words with certain POS tags, such as verbs, and replace them with a placeholder or suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6360137228241296794 verb 1 2 noticed\n",
      "6360137228241296794 verb 5 6 appear\n",
      "6360137228241296794 verb 8 9 getting\n",
      "6360137228241296794 verb 14 15 increasing\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\n",
    "        \"POS\" :\"VERB\", # match verbs\n",
    "    \"OP\":\"*\"           # match 0 or more verbs\n",
    "    }\n",
    "    ]\n",
    "matcher.add(\"verb\", [pattern])\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches[:len(matches)//10]: # limit output\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: A [Span](https://spacy.io/api/span) is a slice from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ever <verb, past tense> how plane seats <verb, non-3rd person singular present> to be <verb, gerund or present participle> smaller and smaller? With <verb, gerund or present participle> numbers of people <verb, gerund or present participle> to the skies, some experts are <verb, gerund or present participle> if <verb, gerund or present participle> such <verb, past participle> out planes is <verb, gerund or present participle> passengers at risk.\\nThey <verb, non-3rd person singular present> that the <verb, gerund or present participle> space on aeroplanes is not only uncomfortable - it's <verb, gerund or present participle> our health and safety in danger.\\nMore than <verb, gerund or present participle> over the arm rest, <verb, gerund or present participle> space on planes <verb, gerund or present participle> our health and safety in danger? This week, a U.S consumer advisory group <verb, past participle> up by the Department of Transportation <verb, past tense> at a public hearing that while the government is happy to <verb, base form> standards for animals <verb, gerund or present participle> on planes, it doesn't <verb, base form> a minimum amount of space for humans.\\n'In a world where animals <verb, non-3rd person singular present> more rights to space and food than humans,' <verb, past tense> Charlie Leocha, consumer representative on the committee.\\xa0'It is time that the DOT and FAA <verb, base form> a stand for humane treatment of passengers.' But could <verb, gerund or present participle> on planes lead to more serious issues than <verb, gerund or present participle> for space in the overhead lockers, <verb, gerund or present participle> elbows and <verb, base form> back kicking? Tests <verb, past participle> by the FAA use planes with a 31 inch pitch, a standard which on some airlines has <verb, past participle> .\\nMany economy seats on United Airlines <verb, non-3rd person singular present> 30 inches of room, while some airlines <verb, non-3rd person singular present> as little as 28 inches .\\nCynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that it <verb, 3rd person singular present> tests on how quickly passengers can <verb, base form> a plane.\\nBut these tests are <verb, past participle> <verb, past participle> <verb, gerund or present participle> planes with 31 inches between each row of seats, a standard which on some airlines has <verb, past participle>, <verb, past tense> the Detroit News.\\nThe distance between two seats from one point on a seat to the same point on the seat behind it is <verb, past participle> as the pitch.\\nWhile most airlines <verb, non-3rd person singular present> to a pitch of 31 inches or above, some <verb, non-3rd person singular present> below this.\\nWhile United Airlines <verb, 3rd person singular present> 30 inches of space, Gulf Air economy seats <verb, non-3rd person singular present> between 29 and 32 inches, Air Asia <verb, 3rd person singular present> 29 inches and Spirit Airlines <verb, 3rd person singular present> just 28 inches.\\nBritish Airways <verb, 3rd person singular present> a seat pitch of 31 inches, while easyJet <verb, 3rd person singular present> 29 inches, Thomson's short haul seat pitch is 28 inches, and Virgin Atlantic's is 30-31.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adapted from https://stackoverflow.com/questions/62785916/spacy-replace-token\n",
    "def replace_word(orig_doc):\n",
    "    text = ''\n",
    "    buffer_start = 0\n",
    "    for _, match_start, _ in matcher(orig_doc):\n",
    "        if match_start > buffer_start:  # If we've skipped over some tokens, let's add those in (with trailing whitespace if available)\n",
    "            text += orig_doc[buffer_start: match_start].text + orig_doc[match_start - 1].whitespace_\n",
    "            \n",
    "        token = orig_doc[match_start]\n",
    "        # tense = token.morph.get('Tense')[0] if token.morph.get('Tense') else \"\"\n",
    "        # long_pos = spacy.explain(token.pos_)\n",
    "        tag = spacy.explain(token.tag_)\n",
    "        replacement = f\"<{tag}>\"\n",
    "        text += replacement + token.whitespace_  # Replace token, with trailing whitespace if available\n",
    "        buffer_start = match_start + 1\n",
    "    text += orig_doc[buffer_start:].text\n",
    "    return text\n",
    "\n",
    "replace_word(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've replaced all the verbs in a given text with a suggestion (that's a tad verbose). \n",
    "\n",
    "However, in a real game of Madlibs, we want to only replace a few verbs, and replace other types of speech too. \n",
    "\n",
    "Let's try finding the number of each POS in a text, as both absolute number and percentage of the word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>Num</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>longPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADV</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VERB</td>\n",
       "      <td>45</td>\n",
       "      <td>0.11</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCONJ</td>\n",
       "      <td>12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>subordinating conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>102</td>\n",
       "      <td>0.24</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PART</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>particle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUX</td>\n",
       "      <td>15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>auxiliary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CCONJ</td>\n",
       "      <td>11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>coordinating conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>40</td>\n",
       "      <td>0.09</td>\n",
       "      <td>punctuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADP</td>\n",
       "      <td>55</td>\n",
       "      <td>0.13</td>\n",
       "      <td>adposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DET</td>\n",
       "      <td>34</td>\n",
       "      <td>0.08</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SPACE</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRON</td>\n",
       "      <td>11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>proper noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NUM</td>\n",
       "      <td>16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>numeral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SYM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>symbol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      POS  Num  Ratio                    longPOS\n",
       "0     ADV    6   0.01                     adverb\n",
       "1    VERB   45   0.11                       verb\n",
       "2   SCONJ   12   0.03  subordinating conjunction\n",
       "3    NOUN  102   0.24                       noun\n",
       "4    PART    5   0.01                   particle\n",
       "5     AUX   15   0.04                  auxiliary\n",
       "6     ADJ   17   0.04                  adjective\n",
       "7   CCONJ   11   0.03   coordinating conjunction\n",
       "8   PUNCT   40   0.09                punctuation\n",
       "9     ADP   55   0.13                 adposition\n",
       "10    DET   34   0.08                 determiner\n",
       "11  SPACE   10   0.02                      space\n",
       "12   PRON   11   0.03                    pronoun\n",
       "13  PROPN   29   0.07                proper noun\n",
       "14    NUM   16   0.04                    numeral\n",
       "15    SYM    0   0.00                     symbol"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = dict()\n",
    "token_count = len(doc)\n",
    "for token in doc:\n",
    "    long_pos = token.pos_\n",
    "    try:\n",
    "        stats[long_pos] = stats[long_pos] + 1\n",
    "    except KeyError:\n",
    "        stats[long_pos] = 0\n",
    "\n",
    "# tabulate in pandas dataframe\n",
    "stats_df = pd.DataFrame(stats.items(), columns=[\"POS\", \"Num\"]) \n",
    "stats_df[\"Ratio\"] = round(stats_df[\"Num\"] /token_count, 2)\n",
    "stats_df[\"longPOS\"] = stats_df[\"POS\"].apply(lambda x:spacy.explain(x))\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>Num</th>\n",
       "      <th>Ratio</th>\n",
       "      <th>longPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>102</td>\n",
       "      <td>0.24</td>\n",
       "      <td>noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADP</td>\n",
       "      <td>55</td>\n",
       "      <td>0.13</td>\n",
       "      <td>adposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VERB</td>\n",
       "      <td>45</td>\n",
       "      <td>0.11</td>\n",
       "      <td>verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PUNCT</td>\n",
       "      <td>40</td>\n",
       "      <td>0.09</td>\n",
       "      <td>punctuation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DET</td>\n",
       "      <td>34</td>\n",
       "      <td>0.08</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>29</td>\n",
       "      <td>0.07</td>\n",
       "      <td>proper noun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NUM</td>\n",
       "      <td>16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>numeral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUX</td>\n",
       "      <td>15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>auxiliary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCONJ</td>\n",
       "      <td>12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>subordinating conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CCONJ</td>\n",
       "      <td>11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>coordinating conjunction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRON</td>\n",
       "      <td>11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>pronoun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SPACE</td>\n",
       "      <td>10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADV</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>adverb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PART</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>particle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SYM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>symbol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      POS  Num  Ratio                    longPOS\n",
       "3    NOUN  102   0.24                       noun\n",
       "9     ADP   55   0.13                 adposition\n",
       "1    VERB   45   0.11                       verb\n",
       "8   PUNCT   40   0.09                punctuation\n",
       "10    DET   34   0.08                 determiner\n",
       "13  PROPN   29   0.07                proper noun\n",
       "6     ADJ   17   0.04                  adjective\n",
       "14    NUM   16   0.04                    numeral\n",
       "5     AUX   15   0.04                  auxiliary\n",
       "2   SCONJ   12   0.03  subordinating conjunction\n",
       "7   CCONJ   11   0.03   coordinating conjunction\n",
       "12   PRON   11   0.03                    pronoun\n",
       "11  SPACE   10   0.02                      space\n",
       "0     ADV    6   0.01                     adverb\n",
       "4    PART    5   0.01                   particle\n",
       "15    SYM    0   0.00                     symbol"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.sort_values(by=[\"Num\"], ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there's a lot of nouns (legitimate tokens we might want to swap out), there's also a large number of punctionation.\n",
    "\n",
    "That's alright. We can just black/whitelist certain POS and specify a ratio of words per POS to swap out (say 10 % of nouns).\n",
    "\n",
    "Let's try setting a ratio, configuring the matcher, and feeding that into the replacer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats builder\n",
    "def get_stats(orig_doc:spacy.tokens.doc.Doc):\n",
    "    \"\"\"\n",
    "    Returns the number of unique POS tags in the doc as {POS : Num} dictionary.\n",
    "    \"\"\"\n",
    "    stats = dict()\n",
    "    token_count = len(doc)\n",
    "    for token in orig_doc:\n",
    "        long_pos = token.pos_ # we can't use the long form explanation any longer because we need it to map in the matcher\n",
    "        try:\n",
    "            stats[long_pos] = stats[long_pos] + 1\n",
    "        except KeyError:\n",
    "            stats[long_pos] = 0\n",
    "    return stats\n",
    "\n",
    "# pattern builder\n",
    "def get_patterns(stats:dict, blacklist:[str]=[], ratio:float=1.0):\n",
    "    \"\"\"\n",
    "    Returns a list of lists of dictionary of POS and number of desired matches\n",
    "    from a given dictionary of {POS : Num}, after removing the blacklisted POS tags.\n",
    "    \"\"\"\n",
    "    assert(ratio >= 0 and ratio <= 1.0)\n",
    "    whitelist = stats\n",
    "    for ban in blacklist:\n",
    "        whitelist.pop(ban, None)\n",
    "    \n",
    "    return [[{\n",
    "            \"POS\": pos,\n",
    "            \"OP\" : f\"{{{math.ceil(num * ratio)}}}\" # each pattern is its own list\n",
    "        }]\n",
    "        for pos, num in whitelist.items()]\n",
    "\n",
    "\n",
    "def replace_word(orig_doc, matches):\n",
    "    \"\"\"\n",
    "    Returns a string where the matches have been replaced by the corresponding POS tag information.\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    buffer_start = 0\n",
    "    for _, match_start, _ in matches:\n",
    "        if match_start > buffer_start:  # If we've skipped over some tokens, let's add those in (with trailing whitespace if available)\n",
    "            text += orig_doc[buffer_start: match_start].text + orig_doc[match_start - 1].whitespace_\n",
    "            \n",
    "        token = orig_doc[match_start]\n",
    "        tag = spacy.explain(token.tag_)\n",
    "        replacement = f\"{{{tag}}}\"\n",
    "        text += replacement + token.whitespace_  # Replace token, with trailing whitespace if available\n",
    "        buffer_start = match_start + 1\n",
    "    text += orig_doc[buffer_start:].text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADV': 6, 'VERB': 45, 'SCONJ': 12, 'NOUN': 102, 'PART': 5, 'AUX': 15, 'ADJ': 17, 'CCONJ': 11, 'PUNCT': 40, 'ADP': 55, 'DET': 34, 'PRON': 11, 'PROPN': 29, 'SPACE': 0, 'NUM': 16, 'SYM': 0}\n",
      "{adverb} noticed how plane seats appear {infinitival \"to\"} be getting smaller and smaller?\n",
      "With increasing numbers of people taking to the skies, some experts are questioning if having such packed out planes is putting passengers at risk.\n",
      "They say that the shrinking space on aeroplanes is {adverb} {adverb} uncomfortable - it's putting our health and safety in danger.\n",
      "More than squabbling over the arm rest, shrinking space on planes putting our health and safety in danger?\n",
      "This week, a U.S consumer advisory group set up by the Department of Transportation said at a public hearing {conjunction, subordinating or preposition} while the government is happy {infinitival \"to\"} set standards for animals flying on planes, it does{adverb} stipulate a minimum amount of space for humans.\n",
      "'In a world where animals have more rights to space and food than humans,' said Charlie Leocha, consumer representative on the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of passengers.' But could crowding on planes lead to {adverb, comparative} serious issues than fighting for space in the overhead lockers, crashing elbows and seat back kicking?\n",
      "Tests conducted by the FAA use planes with a 31 inch pitch, a standard which on some airlines has decreased .\n",
      "Many economy seats on United Airlines have 30 inches of room, while some airlines offer {adverb} little as 28 inches .\n",
      "Cynthia Corbertt, a human factors researcher with the {noun, proper singular} Aviation Administration, that it conducts tests on how {adverb} passengers can leave a plane.\n",
      "But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines has decreased, reported the Detroit News.\n",
      "The distance between two seats from one point on a seat to the same point on the seat behind it is known as the pitch.\n",
      "While most airlines stick to a pitch of 31 inches or {adverb}, some fall below this.\n",
      "While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, Air Asia offers 29 inches and Spirit Airlines offers {adverb} 28 inches.\n",
      "British Airways has a seat pitch of 31 inches, while easyJet has 29 inches, Thomson{possessive ending} short haul seat pitch is 28 inches, and Virgin Atlantic{possessive ending} is 30-31.\n"
     ]
    }
   ],
   "source": [
    "RATIO = 0.1\n",
    "BLACKLIST= [\"determiner\", \"punctuation\"]\n",
    "df = pd.read_csv(\"archive/cnn_dailymail/test.csv\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = df.iloc[0]['article']\n",
    "doc= nlp(text)\n",
    "stats = get_stats(doc)\n",
    "print(stats)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "patterns = get_patterns(stats= stats, blacklist= BLACKLIST, ratio= RATIO )\n",
    "\n",
    "matcher.add(\"PATTERNS\", patterns)\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "with open(\"blanked_passage.txt\", \"w\") as f:\n",
    "    blanked_txt = replace_word(doc, matches)\n",
    "    blanked_txt = blanked_txt.replace(\". \", \".\\n\").replace(\"? \", \"?\\n\")\n",
    "    f.write(blanked_txt)\n",
    "    print(blanked_txt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's looking pretty good! Can you spot a few problems? \n",
    "\n",
    "Problems: \n",
    "1. We might need to blacklist that {infinitival \"to\"}. In fact, blacklisting might not actually be working because the long form POS arent in stats.keys()\n",
    "2. We need to randomise the locations of the replacements. Right now, it's replaced in order. \n",
    "    - Instead of calculating the match ratio, we can implement it as a random chance that's rolled each time we might need to replace a token.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats builder 2\n",
    "def get_stats(orig_doc:spacy.tokens.doc.Doc):\n",
    "    \"\"\"\n",
    "    Returns the number of unique POS tags in the doc as (POS, Num, longPOS) Dataframe.\n",
    "    \"\"\"\n",
    "    stats = dict()\n",
    "    token_count = len(doc)\n",
    "    for token in orig_doc:\n",
    "        try:\n",
    "            stats[token.pos_] = stats[token.pos_] + 1\n",
    "        except KeyError:\n",
    "            stats[token.pos_] = 0\n",
    "    stats_df = pd.DataFrame(stats.items(), columns=[\"POS\", \"Num\"])\n",
    "    stats_df[\"longPOS\"] = stats_df[\"POS\"].apply(lambda x:spacy.explain(x))\n",
    "    return stats_df\n",
    "\n",
    "# pattern builder 2\n",
    "def get_patterns(stats_df:pd.DataFrame, blacklist:[str]=[]):\n",
    "    \"\"\"\n",
    "    Returns a list of lists of dictionary of POS and number of desired matches\n",
    "    from a given Dataframe of (POS, Num, longPOS), after removing the blacklisted POS tags.\n",
    "    \"\"\"\n",
    "    whitelist = stats_df[~stats_df[\"longPOS\"].isin(blacklist)]\n",
    "    return [[{\n",
    "            \"POS\": pos,\n",
    "            \"OP\" : f\"{{,{num}}}\" # each pattern is its own list\n",
    "        }]\n",
    "        for pos, num in zip(whitelist[\"POS\"], whitelist[\"Num\"] )]\n",
    "\n",
    "def get_matches(patterns, matcher, doc, ratio=1.0):\n",
    "    \"\"\"\n",
    "    Use a for loop to get the matches for each pattern.\n",
    "    Take RATIO of each matches and replace them.\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    for pattern in patterns:\n",
    "        matcher.add(\"PATTERN\", [pattern])\n",
    "        match = matcher(doc)\n",
    "        matches.extend(\n",
    "            random.sample(match, math.ceil(ratio * len(match)))\n",
    "        )\n",
    "        matcher.remove(\"PATTERN\")\n",
    "\n",
    "    # sort matches \n",
    "\n",
    "    return sorted(matches, key=lambda x:x[1])\n",
    "\n",
    "# pasted again\n",
    "def replace_word(orig_doc, matches):\n",
    "    \"\"\"\n",
    "    Returns a string where the matches have been replaced by the corresponding POS tag information.\n",
    "    \"\"\"\n",
    "    text = ''\n",
    "    buffer_start = 0\n",
    "    for _, match_start, _ in matches:\n",
    "        if match_start > buffer_start:  # If we've skipped over some tokens, let's add those in (with trailing whitespace if available)\n",
    "            text += orig_doc[buffer_start: match_start].text + orig_doc[match_start - 1].whitespace_\n",
    "        \n",
    "        token = orig_doc[match_start]\n",
    "        tag = spacy.explain(token.tag_)\n",
    "        replacement = f\"{{{tag}}}\"\n",
    "\n",
    "        text += replacement + token.whitespace_ # Replace token, with trailing whitespace if available\n",
    "        buffer_start = match_start + 1\n",
    "    text += orig_doc[buffer_start:].text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ever noticed how plane seats appear to {verb, base form} getting smaller and smaller?\n",
      "With increasing numbers of people {verb, gerund or present participle} {conjunction, subordinating or preposition} the skies, some experts are {verb, gerund or present participle} if having such packed out planes is putting passengers at risk.\n",
      "They say that the shrinking space on aeroplanes is not {adverb} uncomfortable - it's {verb, gerund or present participle} our health and safety in danger.\n",
      "More than squabbling over the arm {noun, singular or mass}, shrinking space on planes putting our health {conjunction, coordinating} safety in danger?\n",
      "This week, a U.S consumer advisory group set {adverb, particle} by the Department of Transportation said {conjunction, subordinating or preposition} a public hearing that {conjunction, subordinating or preposition} the government is {adjective (English), other noun-modifier (Chinese)} to set standards for animals flying on planes, it doesn't stipulate a minimum amount of {noun, singular or mass} for humans.\n",
      "'In a world {wh-adverb} animals have more rights {conjunction, subordinating or preposition} {noun, singular or mass} and food than {noun, plural},' said Charlie Leocha, {noun, singular or mass} representative {conjunction, subordinating or preposition} the committee.Â 'It is time that the DOT and FAA take a stand for humane treatment of {noun, plural}.' But could crowding on planes lead to more serious issues than {verb, gerund or present participle} for space in the overhead lockers, crashing elbows and seat back kicking?\n",
      "Tests conducted by the FAA use planes with a 31 inch pitch, a standard {wh-determiner} on some airlines has decreased .\n",
      "Many economy seats on United Airlines have 30 inches of {noun, singular or mass}, while some airlines offer as little as 28 inches .\n",
      "Cynthia Corbertt, a human factors researcher with the Federal Aviation Administration, that {pronoun, personal} conducts tests on how quickly passengers can leave a plane.\n",
      "But these tests are conducted using planes with 31 inches between each row of seats, a standard which on some airlines {verb, 3rd person singular present} decreased, reported the {noun, proper singular} News.\n",
      "The {noun, singular or mass} between two seats from one point on a {noun, singular or mass} to the same point on the seat behind it is known as the {noun, singular or mass}.\n",
      "While {adjective, superlative} airlines stick to a pitch of 31 inches or above, some fall {conjunction, subordinating or preposition} this.\n",
      "While United Airlines has 30 inches of space, Gulf Air economy seats have between 29 and 32 inches, {noun, proper singular} Asia {verb, 3rd person singular present} 29 inches and Spirit {noun, proper singular} offers just 28 inches.\n",
      "{noun, proper singular} Airways has a seat pitch of 31 inches, while easyJet has {cardinal number} inches, {noun, proper singular}'s short haul seat {noun, singular or mass} is 28 {noun, plural}, {conjunction, coordinating} Virgin Atlantic's is {cardinal number}-31.\n",
      "1.1089999999385327\n"
     ]
    }
   ],
   "source": [
    "start= time.monotonic()\n",
    "RATIO = 0.1\n",
    "BLACKLIST= [\"determiner\", \"punctuation\", \"particle\"]\n",
    "df = pd.read_csv(\"archive/cnn_dailymail/test.csv\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = df.iloc[0]['article']\n",
    "doc= nlp(text)\n",
    "stats_df = get_stats(doc)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "patterns = get_patterns(stats_df= stats_df, blacklist= BLACKLIST)\n",
    "matches = get_matches(patterns, matcher, doc, ratio=RATIO)\n",
    "\n",
    "with open(\"blanked_passage.txt\", \"w\") as f:\n",
    "    blanked_txt = replace_word(doc, matches)\n",
    "    blanked_txt = blanked_txt.replace(\". \", \".\\n\").replace(\"? \", \"?\\n\")\n",
    "    f.write(blanked_txt)\n",
    "    print(blanked_txt)\n",
    "print(time.monotonic()-start)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a little slow, but it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
